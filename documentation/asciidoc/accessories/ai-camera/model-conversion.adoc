== Model deployment

To deploy a new neural network model to the Raspberry Pi AI Camera, complete the following steps:

. Provide a neural network model.
. Quantise and compress the model so that it can run using the resources available on the IMX500 camera module.
. Convert the compressed model to IMX500 format.
. Package the model into a firmware file that can be loaded at runtime onto the camera.

The first three steps will normally be performed on a more powerful computer such as a desktop or server. You must run the final packaging step on a Raspberry Pi.

=== Model creation

The creation of neural network models is beyond the scope of this guide. Existing models can be re-used, or new ones created using popular frameworks like TensorFlow or PyTorch.

For more information, see the official https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera[AITRIOS developer website].

=== Quantisation and compression

Models are quantised and compressed using Sony's Model Compression Toolkit. To install the toolkit, run the following command:

[source,console]
----
$ pip install model_compression_toolkit
----

For more information, see the https://github.com/sony/model_optimization[Sony model optimization GitHub repository].

The Model Compression Toolkit generates a quantised model in the following formats:

* Keras (TensorFlow)
* ONNX (PyTorch)

=== Conversion

To convert a model, first install the converter tools:

[tabs]
======
TensorFlow::
+
[source,console]
----
$ pip install imx500-converter[tf]
----
+
TIP: Always use the same version of TensorFlow you used to compress your model.

PyTorch::
+
[source,console]
----
$ pip install imx500-converter[pt]
----
======

If you need to install both packages, use two separate Python virtual environments. This prevents TensorFlow and PyTorch from causing conflicts with one another.

Next, convert the model:

[tabs]
======
TensorFlow::
+
[source,console]
----
$ imxconv-tf -i <compressed Keras model> -o <output folder>
----

PyTorch::
+
[source,console]
----
$ imxconv-pt -i <compressed ONNX model> -o <output folder>
----
======

Both commands create an output folder that contains a memory usage report and a `packerOut.zip` file.

For optimal use of the memory available to the accelerator on the IMX500 sensor, add `--no-input-persistency` to the above commands. However, this will disable input tensor generation and return to the application for debugging purposes.

For more information on the model conversion process, see the official https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera/documentation/imx500-converter[Sony IMX500 Converter documentation].

=== Packaging

IMPORTANT: You must run this step on a Raspberry Pi.

The final step packages the model into an RPK file. When running the neural network model, we'll upload this file to the AI Camera. Before proceeding, run the following command to install the necessary tools:

[source,console]
----
$ sudo apt install imx500-tools
----

To package the model into an RPK file, run the following command:

[source,console]
----
$ imx500-package -i <path to packerOut.zip> -o <output folder>
----

This command should create a file named `network.rpk` in the output folder. You'll pass the name of this file to your IMX500 camera applications.

For a more comprehensive set of instructions and further specifics on the tools used, see the https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera/documentation/imx500-packager[Sony IMX500 Packager documentation].
