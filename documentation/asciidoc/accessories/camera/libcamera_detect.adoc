=== `libcamera-detect`

`libcamera-detect` is not supplied by default in any Raspberry Pi OS distribution, but can be built by users who have xref:camera.adoc#post-processing-with-tensorflow-lite[installed TensorFlow Lite]. In this case, please refer to the xref:camera.adoc#building-libcamera-and-libcamera-apps[`libcamera-apps` build instructions]. You will need to run `cmake` with `-DENABLE_TFLITE=1`.

This application runs a preview window and monitors the contents using a Google MobileNet v1 SSD (Single Shot Detector) neural network that has been trained to identify about 80 classes of objects using the Coco dataset. It should recognise people, cars, cats and many other objects.

Its starts by running a preview window, and whenever the target object is detected it will perform a full resolution JPEG capture, before returning back to the preview mode to continue monitoring. It provides a couple of additional command line options that do not apply elsewhere:

`--object <name>`

Detect objects with the given `<name>`. The name should be taken from the model's label file.

`--gap <number>`

Wait at least this many frames after a capture before performing another. This is necessary because the neural network does not run on every frame, so it is best to give it a few frames to run again before considering another capture.

Please refer to the xref:camera.adoc#object_detect_tf-stage[TensorFlow Lite object detector] section for more general information on how to obtain and use this model. But as an example, you might spy secretly on your cats while you are away with:

[,bash]
----
libcamera-detect -t 0 -o cat%04d.jpg --lores-width 400 --lores-height 300 --post-process-file object_detect_tf.json --object cat
----
